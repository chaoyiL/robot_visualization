import numpy as np
from scipy.spatial.transform import Rotation
import sys
import os
import cv2
import zarr
import trimesh
import pyrender
from pyrender import RenderFlags
from zarr.storage import ZipStore

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if project_root not in sys.path:
    sys.path.append(project_root)

from replay_buffer import ReplayBuffer
from imagecodecs_numcodecs import register_codecs
register_codecs()

# ä¼ æ„Ÿå™¨é…ç½®
ROBOT_IDS = [0, 1]
SENSOR_KEY_CANDIDATES = {
    'visual': [
        'robot{}_visual',
        'camera{}_rgb',
    ],
    'left_tactile': [
        'robot{}_left_tactile',
        'camera{}_left_tactile',
    ],
    'right_tactile': [
        'robot{}_right_tactile',
        'camera{}_right_tactile',
    ],
    'left_pc': [
        'robot{}_left_tactile_points',
        'camera{}_left_tactile_points',
    ],
    'right_pc': [
        'robot{}_right_tactile_points',
        'camera{}_right_tactile_points',
    ],
}
def transform_quest_to_robot(quest_pos, quest_rot_axis_angle):
    """
    å°†Questå·¦æ‰‹åæ ‡ç³»è½¬æ¢ä¸ºæœºå™¨äººå³æ‰‹åæ ‡ç³»
    
    Questå·¦æ‰‹ç³»ï¼ˆUnityé£æ ¼ï¼‰:
        +X: å³
        +Y: ä¸Š
        +Z: å‰
    
    æœºå™¨äººå³æ‰‹ç³»ï¼ˆROSæ ‡å‡†ï¼‰:
        +X: å‰
        +Y: å·¦
        +Z: ä¸Š
    
    è½¬æ¢åˆ†ä¸¤æ­¥ï¼š
    1. å·¦æ‰‹ç³»â†’å³æ‰‹ç³»ï¼šç¿»è½¬Zè½´
    2. åæ ‡è½´é‡æ˜ å°„ï¼šQuest(å³,ä¸Š,å) â†’ Robot(å‰,å·¦,ä¸Š)
    """
    
    # æ­¥éª¤1ï¼šå·¦æ‰‹ç³»â†’å³æ‰‹ç³»ï¼ˆç¿»è½¬Zè½´ï¼‰
    # Questå·¦æ‰‹(xå³, yä¸Š, zå‰) â†’ Questå³æ‰‹(xå³, yä¸Š, zå)
    quest_pos_rh = quest_pos.copy()
    quest_pos_rh[2] = -quest_pos_rh[2]  # ç¿»è½¬Z
    
    # æ­¥éª¤2ï¼šåæ ‡è½´é‡æ˜ å°„
    # Questå³æ‰‹(xå³, yä¸Š, zå) â†’ Robot(xå‰, yå·¦, zä¸Š)
    T = np.array([
        [ 0,  0, -1],  # Robot_X = -Quest_Z (Queståâ†’Robotå‰)
        [-1,  0,  0],  # Robot_Y = -Quest_X (Questå³â†’Robotå·¦)
        [ 0,  1,  0]   # Robot_Z =  Quest_Y (Questä¸Šâ†’Robotä¸Š)
    ])
    
    robot_pos = quest_pos_rh @ T.T
    
    # æ—‹è½¬è½¬æ¢
    # æ­¥éª¤1ï¼šå·¦æ‰‹ç³»æ—‹è½¬â†’å³æ‰‹ç³»æ—‹è½¬
    quest_rot_rh = quest_rot_axis_angle.copy()
    quest_rot_rh[2] = -quest_rot_rh[2]  # ç¿»è½¬Zè½´çš„æ—‹è½¬åˆ†é‡
    
    # æ­¥éª¤2ï¼šåº”ç”¨åæ ‡è½´é‡æ˜ å°„
    from scipy.spatial.transform import Rotation
    quest_rot = Rotation.from_rotvec(quest_rot_rh)
    quest_rot_matrix = quest_rot.as_matrix()
    
    robot_rot_matrix = T @ quest_rot_matrix @ T.T
    robot_rot = Rotation.from_matrix(robot_rot_matrix)
    robot_rot_axis_angle = robot_rot.as_rotvec()
    
    return robot_pos, robot_rot_axis_angle
def get_transform(pos, rot_axis_angle):
    """è·å–å˜æ¢çŸ©é˜µ"""
    rotation_matrix, _ = cv2.Rodrigues(rot_axis_angle)
    T = np.eye(4)
    T[:3, :3] = rotation_matrix
    T[:3, 3] = pos
    return T

def decode_image(img_data):
    """ç»Ÿä¸€çš„å›¾åƒè§£ç """
    if isinstance(img_data, bytes):
        img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img_data

def load_pointcloud(points_data):
    """ç»Ÿä¸€çš„ç‚¹äº‘åŠ è½½å’Œè¿‡æ»¤"""
    if points_data is None or len(points_data) == 0:
        return np.empty((0, 3), dtype=np.float32)
    points = np.array(points_data, dtype=np.float32)
    if points.ndim != 2 or points.shape[1] != 3:
        return np.empty((0, 3), dtype=np.float32)
    mask = np.any(points != 0, axis=1)
    return points[mask] if np.any(mask) else np.empty((0, 3), dtype=np.float32)

def calc_camera_params(points):
    """è®¡ç®—ç‚¹äº‘çš„ç›¸æœºå‚æ•°"""
    if len(points) == 0:
        return {'center': [0, 0, 40], 'eye': [50, -30, 80], 'up': [0, 0, 1]}
    pts = np.asarray(points, dtype=np.float64)
    center = pts.mean(axis=0)
    extent = pts.max(axis=0) - pts.min(axis=0)
    dist = max(np.max(extent) * 2.5, 1.0)
    eye = center + np.array([dist * 0.2, -dist * 0.1, dist * 1.2])
    return {'center': center.tolist(), 'eye': eye.tolist(), 'up': [0, 0, 1]}

def resize_with_label(img, label, height, color=(255, 255, 255)):
    """è°ƒæ•´å›¾åƒå¤§å°å¹¶æ·»åŠ æ ‡ç­¾"""
    if img is None:
        return None
    h, w = img.shape[:2]
    resized = cv2.resize(img, (int(w * height / h), height))
    cv2.putText(resized, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)
    cv2.putText(resized, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)
    return resized

def hstack_with_sep(images, sep_width=2, sep_color=255):
    """æ°´å¹³æ‹¼æ¥å›¾åƒï¼Œå¸¦åˆ†éš”çº¿"""
    valid = [img for img in images if img is not None]
    if not valid:
        return None
    if len(valid) == 1:
        return valid[0]
    h = valid[0].shape[0]
    sep = np.ones((h, sep_width, 3), dtype=np.uint8) * sep_color
    parts = []
    for i, img in enumerate(valid):
        parts.append(img)
        if i < len(valid) - 1:
            parts.append(sep)
    return np.hstack(parts)

def load_episode_data(replay_buffer, episode_idx):
    """åŠ è½½episodeæ•°æ®"""
    ep_slice = replay_buffer.get_episode_slice(episode_idx)
    data = {f'robot{r}': {
        'poses': [], 'gripper': [],
        'visual': [], 'left_tactile': [], 'right_tactile': [],
        'left_pc': [], 'right_pc': []
    } for r in ROBOT_IDS}
    
    first_tx = {0: None, 1: None}
    keys = set(replay_buffer.keys())

    def _resolve_key(sensor, robot_id):
        for template in SENSOR_KEY_CANDIDATES[sensor]:
            key = template.format(robot_id)
            if key in keys:
                return key
        return None

    resolved_keys = {
        f'robot{r}_{s}': _resolve_key(s, r)
        for r in ROBOT_IDS for s in SENSOR_KEY_CANDIDATES
    }

    # æ£€æŸ¥å¯ç”¨æ•°æ®
    has = {name: (resolved_keys[name] is not None) for name in resolved_keys}
    has['robot1_pose'] = 'robot1_eef_pos' in keys
    has['robot0_gripper'] = 'robot0_gripper_width' in keys
    has['robot1_gripper'] = 'robot1_gripper_width' in keys
    
    for i in range(ep_slice.start, ep_slice.stop):
        for r in ROBOT_IDS:
            prefix = f'robot{r}'
            cam_id = r
            
            # åŠ è½½ä½å§¿
            if r == 0 or has['robot1_pose']:
                # ä»æ•°æ®ä¸­è¯»å–Questå·¦æ‰‹åæ ‡
                quest_pos = replay_buffer[f'robot{r}_eef_pos'][i]
                quest_rot = replay_buffer[f'robot{r}_eef_rot_axis_angle'][i]
                
                # è½¬æ¢åˆ°æœºå™¨äººå³æ‰‹åæ ‡ç³»
                pos, rot = transform_quest_to_robot(quest_pos, quest_rot)
                
                # ç”Ÿæˆå˜æ¢çŸ©é˜µ
                tx = get_transform(pos, rot)
                data[prefix]['poses'].append(tx)
            
            # åŠ è½½å¤¹çˆª
            if has[f'{prefix}_gripper']:
                data[prefix]['gripper'].append(replay_buffer[f'{prefix}_gripper_width'][i][0])
            
            # åŠ è½½å›¾åƒå’Œç‚¹äº‘
            for sensor in SENSOR_KEY_CANDIDATES:
                key = resolved_keys.get(f'{prefix}_{sensor}')
                if not key:
                    continue
                raw = replay_buffer[key][i]
                if 'pc' in sensor:
                    data[prefix][sensor].append(load_pointcloud(raw))
                else:
                    data[prefix][sensor].append(decode_image(raw))
    
    return data, has

def create_combined_image(data, frame_idx, pc_images, world_image, height=250):
    """åˆ›å»ºç»„åˆå›¾åƒ"""
    rows = []
    colors = {0: (0, 0, 255), 1: (0, 255, 0)}  # robot0çº¢è‰², robot1ç»¿è‰²

    if world_image is not None:
        world_row = resize_with_label(world_image, "World 3D", height * 2, (255, 255, 255))
        rows.append(world_row)
    
    for r in ROBOT_IDS:
        prefix = f'robot{r}'
        row_parts = []
        
        # å°†æ‰€æœ‰å›¾åƒæ”¾åœ¨ä¸€èµ·æ°´å¹³æ‹¼æ¥
        all_imgs = []
        
        # ç›¸æœºå›¾åƒ
        for sensor, label in [('visual', 'Visual'), ('left_tactile', 'L-Tact'), ('right_tactile', 'R-Tact')]:
            imgs = data[prefix].get(sensor, [])
            if imgs and frame_idx < len(imgs):
                all_imgs.append(resize_with_label(imgs[frame_idx].copy(), f"R{r} {label}", height, colors[r]))
        
        if all_imgs:
            row_parts.append(hstack_with_sep(all_imgs))
        
        
        
        if row_parts:
            rows.append(hstack_with_sep(row_parts, sep_width=5, sep_color=128))
    
    if not rows:
        return None
    
    # å¯¹é½å®½åº¦
    max_w = max(r.shape[1] for r in rows)
    aligned = []
    for row in rows:
        if row.shape[1] < max_w:
            pad = np.zeros((row.shape[0], max_w - row.shape[1], 3), dtype=np.uint8)
            row = np.hstack([row, pad])
        aligned.append(row)
    
    sep = np.ones((5, max_w, 3), dtype=np.uint8) * 128
    if len(aligned) == 1:
        return aligned[0]
    stacked = []
    for i, row in enumerate(aligned):
        stacked.append(row)
        if i < len(aligned) - 1:
            stacked.append(sep)
    return np.vstack(stacked)

def _lookat_camera_pose(eye, center, up):
    eye = np.array(eye, dtype=np.float64)
    center = np.array(center, dtype=np.float64)
    up = np.array(up, dtype=np.float64)
    f = center - eye
    f = f / (np.linalg.norm(f) + 1e-9)
    u = up / (np.linalg.norm(up) + 1e-9)
    s = np.cross(f, u)
    s = s / (np.linalg.norm(s) + 1e-9)
    u = np.cross(s, f)
    m = np.eye(4)
    m[0, :3] = s
    m[1, :3] = u
    m[2, :3] = -f
    m[:3, 3] = -m[:3, :3] @ eye
    return np.linalg.inv(m)

def _quest_controller_mesh(is_left=True):
    """åŠ è½½Questæ‰‹æŸ„STLæ¨¡å‹"""
    import os
    mesh_file = 'src/meshes/Oculus_Meta_Quest_Touch_Plus_Controller_Left.stl' if is_left else 'src/meshes/Oculus_Meta_Quest_Touch_Plus_Controller_Right.stl'
    
    if not os.path.exists(mesh_file):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç®€å•åœ†æŸ±ä½“
        cyl = trimesh.creation.cylinder(radius=0.02, height=0.15, sections=16)
        rgba = np.array([0.3, 0.3, 0.8, 1.0])
        cyl.visual.vertex_colors = (rgba * 255).astype(np.uint8)
        return pyrender.Mesh.from_trimesh(cyl, smooth=False)
    
    # åŠ è½½STL
    mesh = trimesh.load(mesh_file)
    
    # è°ƒæ•´å¤§å°ï¼ˆQuestæ‰‹æŸ„å®é™…å°ºå¯¸è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦ç¼©æ”¾ï¼‰
    scale = 0.001  # STLå•ä½å¯èƒ½æ˜¯mmï¼Œè½¬ä¸ºm
    mesh.apply_scale(scale)
    
    # è®¾ç½®é¢œè‰²
    rgba = np.array([0.3, 0.3, 0.8, 1.0])
    mesh.visual.vertex_colors = (rgba * 255).astype(np.uint8)
    
    return pyrender.Mesh.from_trimesh(mesh, smooth=True)

def _axis_mesh(size=0.05):
    axis = trimesh.creation.axis(origin_size=size * 0.2, axis_length=size)
    return pyrender.Mesh.from_trimesh(axis, smooth=False)

def _pointcloud_mesh(points, color=[1.0, 1.0, 0.0]):
    if len(points) == 0:
        return None
    pts = np.asarray(points, dtype=np.float64)
    colors = np.tile(np.array(color, dtype=np.float64), (pts.shape[0], 1))
    return pyrender.Mesh.from_points(pts, colors=colors)

def _cylinder_between(p0, p1, radius, color):
    v = p1 - p0
    h = np.linalg.norm(v)
    if h < 1e-6:
        return None
    cyl = trimesh.creation.cylinder(radius=radius, height=h, sections=12)
    T = trimesh.geometry.align_vectors([0, 0, 1], v / h)
    cyl.apply_transform(T)
    cyl.apply_translation(p0 + v * 0.5)
    rgba = np.array(list(color) + [1.0])
    cyl.visual.vertex_colors = (rgba * 255).astype(np.uint8)
    return cyl

def _line_mesh(points, color=[1.0, 0.0, 0.0], radius=0.01):
    if len(points) < 2:
        return None
    pts = np.asarray(points, dtype=np.float64)
    meshes = []
    for i in range(len(pts) - 1):
        cyl = _cylinder_between(pts[i], pts[i + 1], radius, color)
        if cyl is not None:
            meshes.append(cyl)
    if not meshes:
        return None
    merged = trimesh.util.concatenate(meshes)
    return pyrender.Mesh.from_trimesh(merged, smooth=False)

def _placeholder_cad_box():
    # TODO: Replace with real CAD model mesh when available.
    box = trimesh.creation.box(extents=[0.03, 0.1, 0.03])
    box.visual.vertex_colors = np.tile(np.array([180, 180, 180, 255], dtype=np.uint8), (len(box.vertices), 1))
    return pyrender.Mesh.from_trimesh(box, smooth=False)

def load_controller_mesh(is_left=True):
    """åŠ è½½Questæ‰‹æŸ„STL"""
    import os
    filename = 'controller_left_simple.stl' if is_left else 'controller_right_simple.stl'
    filepath = os.path.join('src', 'meshes', filename)
    
    if not os.path.exists(filepath):
        return None
    
    mesh = trimesh.load(filepath)
    mesh.apply_scale(0.002)  # mmè½¬mï¼Œæ”¾å¤§2å€
    mesh.visual.vertex_colors = np.array([100, 100, 200, 255], dtype=np.uint8)
    
    return pyrender.Mesh.from_trimesh(mesh, smooth=True)

def load_gripper_mesh():
    """åŠ è½½çœŸå®å¤¹çˆªSTLæ¨¡å‹"""
    import os
    filepath = 'src/meshes/å¤¹çˆª.STL'
    
    if not os.path.exists(filepath):
        return None
    
    mesh = trimesh.load(filepath)
    mesh.apply_scale(0.002)  # mmè½¬mï¼Œæ”¾å¤§2å€
    
    # å°†æ¨¡å‹ä¸­å¿ƒç§»åˆ°åŸç‚¹
    center = (mesh.bounds[0] + mesh.bounds[1]) / 2
    mesh.apply_translation(-center)
    
    # è®¾ç½®é¢œè‰²
    mesh.visual.vertex_colors = np.array([180, 180, 180, 255], dtype=np.uint8)
    
    return pyrender.Mesh.from_trimesh(mesh, smooth=True)



def load_gripper_pair():
    """åŠ è½½ä¸€å¯¹å¯¹ç§°çš„å¤¹çˆª"""
    import os
    filepath = 'src/meshes/å¤¹çˆª.STL'
    
    if not os.path.exists(filepath):
        return None, None
    
    mesh_base = trimesh.load(filepath)
    mesh_base.apply_scale(0.002)
    center = (mesh_base.bounds[0] + mesh_base.bounds[1]) / 2
    mesh_base.apply_translation(-center)
    
    # å·¦å¤¹çˆª
    mesh_left = mesh_base.copy()
    mesh_left.visual.vertex_colors = np.array([180, 180, 180, 255], dtype=np.uint8)
    left_gripper = pyrender.Mesh.from_trimesh(mesh_left, smooth=True)
    
    # å³å¤¹çˆªï¼ˆYè½´é•œåƒï¼‰
    mesh_right = mesh_base.copy()
    mirror = np.eye(4)
    mirror[1, 1] = -1
    mesh_right.apply_transform(mirror)
    mesh_right.visual.vertex_colors = np.array([180, 180, 180, 255], dtype=np.uint8)
    right_gripper = pyrender.Mesh.from_trimesh(mesh_right, smooth=True)
    
    return left_gripper, right_gripper


def _gripper_boxes(opening_width, color=(1.0, 0.0, 0.0)):
    """Create two symmetric gripper boxes around the tool frame.

    opening_width: distance between inner faces (meters)
    """
    length = 0.15
    width = 0.09
    height = 0.09
    half_offset = max(opening_width * 0.5, 0.0) + width * 0.5
    extents = [length, width, height]

    def _box_mesh():
        box = trimesh.creation.box(extents=extents)
        rgba = np.array([color[0], color[1], color[2], 1.0])
        box.visual.vertex_colors = (rgba * 255).astype(np.uint8)
        return pyrender.Mesh.from_trimesh(box, smooth=False)

    left_mesh = _box_mesh()
    right_mesh = _box_mesh()

    left_pose = np.eye(4)
    right_pose = np.eye(4)
    x_offset = 0.03
    left_pose[:3, 3] = np.array([x_offset, -half_offset, 0.0])
    right_pose[:3, 3] = np.array([x_offset, half_offset, 0.0])
    return (left_mesh, left_pose), (right_mesh, right_pose)

class CombinedVisualizer:
    def __init__(self, replay_buffer, episodes, record_mode=False, record_episode=0, 
                 output_video=None, record_fps=30, continue_after_record=False):
        self.rb = replay_buffer
        self.episodes = episodes
        self.ep_idx = record_episode if record_mode else 0
        self.frame_idx = 0
        self.record_mode = record_mode
        self.output_video = output_video
        self.record_fps = record_fps
        self.continue_after_record = continue_after_record
        
        self.load_episode()
        self.setup_renderers()
        
        if record_mode:
            self.record_episode()
            if not continue_after_record:
                print(" å½•åˆ¶å®Œæˆï¼Œé€€å‡ºç¨‹åº")
                return
        
        self.print_help()
        self.run()
    
    def load_episode(self):
        """åŠ è½½å½“å‰episode"""
        ep_id = self.episodes[self.ep_idx]
        self.data, self.has = load_episode_data(self.rb, ep_id)
        self.frame_idx = 0
        self.setup_camera_params()
        print(f" åŠ è½½ Episode {ep_id} ({self.ep_idx + 1}/{len(self.episodes)}), å¸§æ•°: {len(self.data['robot0']['poses'])}")
    
    def setup_camera_params(self):
        """è®¾ç½®ç‚¹äº‘ç›¸æœºå‚æ•°"""
        self.cam_params = {}
        for r in ROBOT_IDS:
            for side in ['left', 'right']:
                key = f'robot{r}_{side}_pc'
                pcs = self.data[f'robot{r}'][f'{side}_pc']
                # æ‰¾ç¬¬ä¸€ä¸ªéç©ºç‚¹äº‘è®¾ç½®ç›¸æœº
                params = None
                for pc in pcs:
                    if len(pc) > 0:
                        params = calc_camera_params(pc)
                        break
                self.cam_params[key] = params or calc_camera_params(np.empty((0, 3)))
    
    def setup_renderers(self):
        """åˆå§‹åŒ–æ¸²æŸ“å™¨"""
        self.render_size = (400, 300)
        self.world_render_size = (self.render_size[0] * 2, self.render_size[1] * 2)
        self.renderers = {}
        
        # ç‚¹äº‘æ¸²æŸ“å™¨
        for r in ROBOT_IDS:
            for side in ['left', 'right']:
                self.renderers[f'robot{r}_{side}_pc'] = self._create_renderer()
        
        # ç»Ÿä¸€ä¸–ç•Œåæ ‡ç³»æ¸²æŸ“å™¨
        self.renderers['world'] = self._create_renderer(size=self.world_render_size)
    
    def _create_renderer(self, size=None):
        """åˆ›å»ºå•ä¸ªæ¸²æŸ“å™¨"""
        try:
            w, h = size if size is not None else self.render_size
            return pyrender.OffscreenRenderer(w, h)
        except Exception as exc:
            raise RuntimeError(f"æ— æ³•åˆ›å»ºæ¸²æŸ“å™¨: {exc}")
    
    def render_pointcloud(self, points, renderer, cam_params):
        """æ¸²æŸ“ç‚¹äº‘"""
        scene = pyrender.Scene(bg_color=[0.1, 0.1, 0.1, 1.0])
        pc_mesh = _pointcloud_mesh(points, color=[1.0, 1.0, 0.0])
        if pc_mesh:
            scene.add(pc_mesh)
        scene.add(_axis_mesh(size=0.05))

        cam_pose = _lookat_camera_pose(cam_params['eye'], cam_params['center'], cam_params['up'])
        camera = pyrender.PerspectiveCamera(yfov=np.deg2rad(60.0))
        scene.add(camera, pose=cam_pose)
        light = pyrender.DirectionalLight(color=np.ones(3), intensity=4.0)
        scene.add(light, pose=cam_pose)

        color, _ = renderer.render(scene, flags=RenderFlags.RGBA)
        return color[:, :, :3]
    
    def render_trajectory(self, poses, current_idx, renderer, color, gripper_width=None):
        """æ¸²æŸ“è½¨è¿¹"""
        scene = pyrender.Scene(bg_color=[0.1, 0.1, 0.1, 1.0])

        if not poses or current_idx >= len(poses):
            cam_pose = _lookat_camera_pose([0.5, -0.3, 0.8], [0, 0, 0], [0, 0, 1])
            camera = pyrender.PerspectiveCamera(yfov=np.deg2rad(60.0))
            scene.add(camera, pose=cam_pose)
            light = pyrender.DirectionalLight(color=np.ones(3), intensity=4.0)
            scene.add(light, pose=cam_pose)
            color_img, _ = renderer.render(scene, flags=RenderFlags.RGBA)
            return color_img[:, :, :3]

        pts = np.array([p[:3, 3] for p in poses[:current_idx + 1]], dtype=np.float64)

        line_mesh = _line_mesh(pts, color=color, radius=0.01)
        if line_mesh:
            scene.add(line_mesh)

        pts_mesh = _pointcloud_mesh(pts, color=color)
        if pts_mesh:
            scene.add(pts_mesh)

        frame_axis = _axis_mesh(size=0.05)
        frame_pose = poses[current_idx]
        scene.add(frame_axis, pose=frame_pose)

        placeholder_cad = _placeholder_cad_box()
        cad_offset = np.eye(4)
        cad_offset[0, 3] = -0.05
        scene.add(placeholder_cad, pose=frame_pose @ cad_offset)

        if gripper_width is not None:
            (left_mesh, left_pose), (right_mesh, right_pose) = _gripper_boxes(gripper_width)
            scene.add(left_mesh, pose=frame_pose @ left_pose)
            scene.add(right_mesh, pose=frame_pose @ right_pose)
            
            # Questæ‰‹æŸ„ï¼ˆå‚ç›´å‘ä¸Šï¼‰
            ctrl = _quest_controller_mesh(is_left=(r==0))
            if ctrl:
                from scipy.spatial.transform import Rotation
                ctrl_tf = np.eye(4)
                # æ—‹è½¬90åº¦ä½¿å…¶å‚ç›´
                rot = Rotation.from_euler('y', 90, degrees=True).as_matrix()
                ctrl_tf[:3, :3] = rot
                ctrl_tf[:3, 3] = [0, 0, 0.03]  # åœ¨åº•åº§ä¸Šæ–¹
                scene.add(ctrl, pose=frame_pose @ ctrl_tf)
                

        origin_axis = _axis_mesh(size=0.03)
        scene.add(origin_axis, pose=np.eye(4))

        center = pts.mean(axis=0)
        extent = pts.max(axis=0) - pts.min(axis=0)
        dist = max(np.max(extent) * 2.0, 0.3)
        eye = center + np.array([dist * 0.6, -dist * 0.4, dist * 0.8])
        cam_pose = _lookat_camera_pose(eye, center, [0, 0, 1])
        camera = pyrender.PerspectiveCamera(yfov=np.deg2rad(60.0))
        scene.add(camera, pose=cam_pose)
        light = pyrender.DirectionalLight(color=np.ones(3), intensity=4.0)
        scene.add(light, pose=cam_pose)

        color_img, _ = renderer.render(scene, flags=RenderFlags.RGBA)
        return color_img[:, :, :3]

    def render_world_scene(self, current_idx):
        """ç»Ÿä¸€ä¸–ç•Œåæ ‡ç³»æ¸²æŸ“"""
        scene = pyrender.Scene(bg_color=[0.1, 0.1, 0.1, 1.0])
        scene.add(_axis_mesh(size=0.15))

        colors = {0: [1, 0, 0], 1: [0, 1, 0]}
        all_pts = []

        for r in ROBOT_IDS:
            prefix = f'robot{r}'
            poses = self.data[prefix].get('poses', [])
            if not poses or current_idx >= len(poses):
                continue

            pts = np.array([p[:3, 3] for p in poses[:current_idx + 1]], dtype=np.float64)
            all_pts.append(pts)

            line_mesh = _line_mesh(pts, color=colors[r], radius=0.01)
            if line_mesh:
                scene.add(line_mesh)

            pts_mesh = _pointcloud_mesh(pts, color=colors[r])
            if pts_mesh:
                scene.add(pts_mesh)

            frame_pose = poses[current_idx]
            scene.add(_axis_mesh(size=0.06), pose=frame_pose)
            cad_offset = np.eye(4)
            cad_offset[0, 3] = -0.05
            scene.add(_placeholder_cad_box(), pose=frame_pose @ cad_offset)

            gripper = self.data[prefix].get('gripper', [])
            if gripper and current_idx < len(gripper):
                # åŠ è½½ä¸€å¯¹çœŸå®å¤¹çˆª
                left_gripper, right_gripper = load_gripper_pair()
                if left_gripper and right_gripper:
                    # å·¦å¤¹çˆª
                    left_tf = np.eye(4)
                    left_tf[:3, 3] = [0.05, -0.06, -0.03]
                    scene.add(left_gripper, pose=frame_pose @ left_tf)
                    
                    # å³å¤¹çˆª
                    right_tf = np.eye(4)
                    right_tf[:3, 3] = [0.05, 0.06, -0.03]
                    scene.add(right_gripper, pose=frame_pose @ right_tf)
                else:
                    # å¤‡ç”¨
                    (left_mesh, left_pose), (right_mesh, right_pose) = _gripper_boxes(float(gripper[current_idx]))
                    scene.add(left_mesh, pose=frame_pose @ left_pose)
                    scene.add(right_mesh, pose=frame_pose @ right_pose)
            
            # æ‰‹è…•è¿æ¥ä»¶ï¼ˆåœ†æŸ±ï¼‰
            wrist = trimesh.creation.cylinder(radius=0.02, height=0.04, sections=16)
            wrist.visual.vertex_colors = np.array([150, 150, 150, 255], dtype=np.uint8)
            wrist_mesh = pyrender.Mesh.from_trimesh(wrist, smooth=False)
            wrist_tf = np.eye(4)
            wrist_tf[:3, 3] = [0, 0, 0.01]  # æ‰‹æŸ„ä¸‹æ–¹
            scene.add(wrist_mesh, pose=frame_pose @ wrist_tf)
            
            # å¤¹çˆªåº•åº§
            base = trimesh.creation.box(extents=[0.04, 0.16, 0.025])
            base.visual.vertex_colors = np.array([130, 130, 130, 255], dtype=np.uint8)
            base_mesh = pyrender.Mesh.from_trimesh(base, smooth=False)
            base_tf = np.eye(4)
            base_tf[:3, 3] = [0, 0, -0.01]  # æ‰‹è…•ä¸‹æ–¹
            scene.add(base_mesh, pose=frame_pose @ base_tf)
            
            # Questæ‰‹æŸ„ï¼ˆå‚ç›´å‘ä¸Šï¼‰
            ctrl = _quest_controller_mesh(is_left=(r==0))
            if ctrl:
                from scipy.spatial.transform import Rotation
                ctrl_tf = np.eye(4)
                # æ—‹è½¬90åº¦ä½¿å…¶å‚ç›´
                rot = Rotation.from_euler('y', 90, degrees=True).as_matrix()
                ctrl_tf[:3, :3] = rot
                ctrl_tf[:3, 3] = [0, 0, 0.03]  # åœ¨åº•åº§ä¸Šæ–¹
                scene.add(ctrl, pose=frame_pose @ ctrl_tf)
                

        if not all_pts:
            cam_pose = _lookat_camera_pose([0.5, -0.3, 0.8], [0, 0, 0], [0, 0, 1])
        else:
            pts = np.vstack(all_pts)
            center = pts.mean(axis=0)
            extent = pts.max(axis=0) - pts.min(axis=0)
            dist = max(np.max(extent) * 2.0, 0.3)
            eye = center + np.array([-dist * 1.5, 0, dist * 0.05])
            cam_pose = _lookat_camera_pose(eye, center, [0, 0, 1])

        camera = pyrender.PerspectiveCamera(yfov=np.deg2rad(60.0))
        scene.add(camera, pose=cam_pose)
        light = pyrender.DirectionalLight(color=np.ones(3), intensity=4.0)
        scene.add(light, pose=cam_pose)

        color_img, _ = self.renderers['world'].render(scene, flags=RenderFlags.RGBA)
        return color_img[:, :, :3]
    
    def get_frame_images(self):
        """è·å–å½“å‰å¸§æ‰€æœ‰æ¸²æŸ“å›¾åƒ"""
        pc_images = {}
        world_image = self.render_world_scene(self.frame_idx)
        
        for r in ROBOT_IDS:
            prefix = f'robot{r}'
            
            # ç‚¹äº‘
            for side in ['left', 'right']:
                key = f'{prefix}_{side}_pc'
                pcs = self.data[prefix].get(f'{side}_pc', [])
                if pcs and self.frame_idx < len(pcs):
                    pc_images[key] = self.render_pointcloud(
                        pcs[self.frame_idx], self.renderers[key], self.cam_params[key])
            
        
        return pc_images, world_image
    
    def create_info_bar(self, frame_idx, width, height=120):
        """åˆ›å»ºä¿¡æ¯æ """
        bar = np.zeros((height, width, 3), dtype=np.uint8)
        bar[:] = [30, 30, 30]
        
        ep_id = self.episodes[self.ep_idx]
        max_frames = len(self.data['robot0']['poses'])
        
        lines = [f"Episode {ep_id} ({self.ep_idx + 1}/{len(self.episodes)}) | Frame {frame_idx}/{max_frames - 1}"]
        
        for r in ROBOT_IDS:
            prefix = f'robot{r}'
            poses = self.data[prefix].get('poses', [])
            if poses and frame_idx < len(poses):
                pos = poses[frame_idx][:3, 3]
                lines.append(f"Robot{r} Pose: [{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}]")
            
            gripper = self.data[prefix].get('gripper', [])
            if gripper and frame_idx < len(gripper):
                lines.append(f"Robot{r} Gripper: {gripper[frame_idx]:.4f}m")
        
        # ç‚¹äº‘ä¿¡æ¯
            pc_info = []
        for r in ROBOT_IDS:
            for side in ['left', 'right']:
                pcs = self.data[f'robot{r}'].get(f'{side}_pc', [])
                if pcs and frame_idx < len(pcs):
                    pc_info.append(f"R{r}-{side[0].upper()}:{len(pcs[frame_idx])}")
        if pc_info:
            lines.append(f"Point Clouds: {' | '.join(pc_info)}")
        
        for i, line in enumerate(lines):
            cv2.putText(bar, line, (10, 20 + i * 18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        
        return bar
    
    def render_frame(self, frame_idx):
        """æ¸²æŸ“å•å¸§"""
        self.frame_idx = frame_idx
        pc_images, world_image = self.get_frame_images()
        combined = create_combined_image(self.data, frame_idx, pc_images, world_image)
        
        if combined is None:
            return None
        
        info_bar = self.create_info_bar(frame_idx, combined.shape[1])
        return np.vstack([combined, info_bar])
    
    def update_display(self):
        """æ›´æ–°æ˜¾ç¤º"""
        frame = self.render_frame(self.frame_idx)
        if frame is not None:
            cv2.imshow("Combined View", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
    
    def record_episode(self):
        """å½•åˆ¶å½“å‰episode"""
        max_frames = len(self.data['robot0']['poses'])
        print(f" å¼€å§‹å½•åˆ¶ Episode {self.episodes[self.ep_idx]}, å¸§æ•°: {max_frames}, FPS: {self.record_fps}")
        
        # è·å–ç¬¬ä¸€å¸§ç¡®å®šå°ºå¯¸
        first_frame = self.render_frame(0)
        if first_frame is None:
            print(" æ— æ³•ç”Ÿæˆå¸§ï¼Œå½•åˆ¶å¤±è´¥")
            return
        
        h, w = first_frame.shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(self.output_video, fourcc, self.record_fps, (w, h))
        
        if not writer.isOpened():
            print(f" æ— æ³•åˆ›å»ºè§†é¢‘æ–‡ä»¶: {self.output_video}")
            return
        
        for i in range(max_frames):
            frame = self.render_frame(i)
            if frame is not None:
                writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
            if (i + 1) % 10 == 0:
                print(f"   è¿›åº¦: {i + 1}/{max_frames} ({(i + 1) / max_frames * 100:.1f}%)")
        
        writer.release()
        print(f" å½•åˆ¶å®Œæˆ: {self.output_video}")
        self.frame_idx = 0
    
    def print_help(self):
        """æ‰“å°å¸®åŠ©"""
        print("\n" + "=" * 50)
        print(" æ§åˆ¶: A/D=å‰/åå¸§  W/S=å‰/åEpisode  R=é‡ç½®è§†è§’  Q=é€€å‡º")
        print("=" * 50 + "\n")
    
    def run(self):
        """è¿è¡Œå¯è§†åŒ–å¾ªç¯"""
        while True:
            self.update_display()
            key = cv2.waitKey(30) & 0xFF
            
            if key in [ord('d'), ord('D')]:
                max_f = len(self.data['robot0']['poses'])
                if self.frame_idx < max_f - 1:
                    self.frame_idx += 1
                elif self.ep_idx < len(self.episodes) - 1:
                    self.ep_idx += 1
                    self.load_episode()
            elif key in [ord('a'), ord('A')]:
                if self.frame_idx > 0:
                    self.frame_idx -= 1
            elif key in [ord('w'), ord('W')]:
                if self.ep_idx < len(self.episodes) - 1:
                    self.ep_idx += 1
                    self.load_episode()
            elif key in [ord('s'), ord('S')]:
                if self.ep_idx > 0:
                    self.ep_idx -= 1
                    self.load_episode()
            elif key in [ord('r'), ord('R')]:
                self.setup_camera_params()
                print("ğŸ“· é‡ç½®è§†è§’")
            elif key in [ord('q'), ord('Q')]:
                print("ğŸ‘‹ é€€å‡º")
                break
        
        cv2.destroyAllWindows()

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Combined visualizer')
    parser.add_argument('zarr_path', nargs='?', 
                       default='C:\\Users\\ruich\\Downloads\\_0115_bi_pick_and_place_2ver.zarr.zip')
    parser.add_argument('--record', type=bool, default=True)
    parser.add_argument('--record_episode', type=int, default=1)
    parser.add_argument('--output_video', type=str, default=None)
    parser.add_argument('--fps', type=int, default=30)
    parser.add_argument('--continue_after_record', type=bool, default=True)
    
    args = parser.parse_args()
    
    if not os.path.exists(args.zarr_path):
        print(f" æ‰¾ä¸åˆ°æ–‡ä»¶: {args.zarr_path}")
        return
    
    print(f" åŠ è½½: {args.zarr_path}")
    
    store = ZipStore(args.zarr_path, mode='r')
    try:
        root = zarr.open_group(store=store, mode='r')
        rb = ReplayBuffer.create_from_group(root)
        print(f" åŠ è½½å®Œæˆ, å¸§æ•°: {rb.n_steps}, Episodes: {rb.n_episodes}")

        if args.record and args.record_episode >= rb.n_episodes:
            print(f" Episode {args.record_episode} è¶…å‡ºèŒƒå›´ (å…± {rb.n_episodes} ä¸ª)")
            return

        if args.record and args.output_video is None:
            import datetime
            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            name = os.path.basename(args.zarr_path).replace('.zarr.zip', '')
            args.output_video = f"recorded_ep{args.record_episode}_{name}_{ts}.mp4"

        CombinedVisualizer(rb, np.arange(rb.n_episodes), args.record, args.record_episode,
                           args.output_video, args.fps, args.continue_after_record)
    finally:
        store.close()

if __name__ == "__main__":
    main()


